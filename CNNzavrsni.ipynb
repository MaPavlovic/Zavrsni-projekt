{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaPavlovic/Zavrsni-projekt/blob/main/CNNzavrsni.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaKdHdUq3JoV",
        "outputId": "079ef6eb-c186-4506-cbc3-68065ceb40ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch==1.8.0 in /usr/local/lib/python3.7/dist-packages (1.8.0)\n",
            "Requirement already satisfied: torchtext==0.9.0 in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: torchvision==0.9.0 in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (4.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (2.23.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2.10)\n"
          ]
        }
      ],
      "source": [
        "# This is needed so we can use torchtext.legacy\n",
        "!pip install torch==1.8.0 torchtext==0.9.0 torchvision==0.9.0 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SSrxw1eyxF5S"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import numpy as np\n",
        "import spacy\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdZmBeIV_91w",
        "outputId": "b8217ee9-89a3-4b46-e093-29c06ea655a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['I', 'have', 'never', 'seen', 'such', 'terrible', 'performances', 'in', 'all', 'my', 'life.<br', '/><br', '/>Everyone', 'in', 'the', 'entire', 'film', 'was', 'absolute', 'rubbish.<br', '/><br', '/>Not', 'one', 'decent', 'actor', '/', 'actress', 'in', 'the', 'whole', 'film', ',', 'it', 'was', 'a', 'joke.<br', '/><br', '/>Reminded', 'me', 'of', 'drama', 'at', 'school', '...'], 'label': 'neg'}\n"
          ]
        }
      ],
      "source": [
        "TEXT = data.Field(tokenize = 'spacy', \n",
        "                  tokenizer_language = 'en_core_web_sm',\n",
        "                  batch_first = True)\n",
        "LABEL = data.LabelField(dtype = torch.float)\n",
        "\n",
        "# The following code automatically downloads the IMDb dataset\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "train_data, valid_data = train_data.split()\n",
        "\n",
        "# Example of the data\n",
        "print(vars(train_data.examples[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7b0LlkoTCMdw"
      },
      "outputs": [],
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TWMI7yEaKF-4"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "InzhOH_0LVTg"
      },
      "outputs": [],
      "source": [
        "class CNN1d(nn.Module):\n",
        "    \"\"\"Class that defines a model of an 1-dimensional convolutional layer\"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "        \"\"\"Init function that creates word embeddings from the input words(self.embedding),\n",
        "        specifys the convolution with different filter sizes(self.convs) and adds a fully \n",
        "        connected layer for final predictions(self.fc)\n",
        "        \"\"\"\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx) \n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv1d(in_channels = embedding_dim, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = fs)\n",
        "                                    for fs in filter_sizes\n",
        "                                    ])\n",
        "        \n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim) \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \"\"\"Forward path of the network, iterate through the list applying each\n",
        "        convolutional layer to get a list of convolutional outputs\n",
        "        \"\"\"\n",
        "\n",
        "        embedded = self.embedding(text).permute(0, 2, 1)      \n",
        "        \n",
        "        # Convolution Layer, apply ReLU activation function\n",
        "        conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
        "            \n",
        "        # Pooling Layer, reduce dimensionality\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        \n",
        "        # Dropout Layer\n",
        "        drop = self.dropout(torch.cat(pooled, dim = 1))    \n",
        "        return self.fc(drop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JAzEQWlwNOlB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de590154-b118-4842-9272-1086a6c21e43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
            "        ...,\n",
            "        [ 0.1897, -0.0174,  0.6258,  ..., -0.3503,  0.0343,  0.8224],\n",
            "        [-0.0211, -0.1949, -0.4826,  ...,  0.1153,  0.1912, -0.4851],\n",
            "        [-0.8699,  0.0444, -0.4751,  ...,  0.0196, -0.6144,  0.8288]])\n"
          ]
        }
      ],
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [3,4,5]\n",
        "OUTPUT_DIM = 1\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model = CNN1d(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
        "\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NneY1bDhNbAf"
      },
      "outputs": [],
      "source": [
        "# Network optimizer\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ez7BBu69P1NP"
      },
      "outputs": [],
      "source": [
        "def accuracy(preds, y):\n",
        "    \"\"\"Function that returns accuracy per batch, eg. 8/10 will\n",
        "    return 0.8. Sends the predictions to a sigmoid function,\n",
        "    squashing the values between 0 and 1.\n",
        "    \"\"\"\n",
        "\n",
        "    correct = (torch.round(torch.sigmoid(preds)) == y).float() \n",
        "    return correct.sum() / len(correct)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    \"\"\"Function thath tracks epoch training time\"\"\"\n",
        "\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eP6bK3LqQSN2"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \"\"\"Function that trains the model with the data, optimizer and loss function.\"\"\"\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        acc = accuracy(predictions, batch.label)\n",
        "        # Back propagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \"\"\"Function that evaluates the model performance\"\"\"\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Phn_Z7YBRDVm",
        "outputId": "8dc51e27-7607-4392-ee0d-72db19b5eaa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 7m 1s\n",
            "\tTrain Loss: 0.652 | Train Acc: 61.27%\n",
            "\t Val. Loss: 0.505 |  Val. Acc: 78.01%\n",
            "Epoch: 02 | Epoch Time: 7m 14s\n",
            "\tTrain Loss: 0.432 | Train Acc: 80.20%\n",
            "\t Val. Loss: 0.370 |  Val. Acc: 83.98%\n",
            "Epoch: 03 | Epoch Time: 6m 56s\n",
            "\tTrain Loss: 0.308 | Train Acc: 87.42%\n",
            "\t Val. Loss: 0.320 |  Val. Acc: 86.54%\n",
            "Epoch: 04 | Epoch Time: 6m 58s\n",
            "\tTrain Loss: 0.224 | Train Acc: 91.20%\n",
            "\t Val. Loss: 0.313 |  Val. Acc: 86.98%\n",
            "Epoch: 05 | Epoch Time: 6m 51s\n",
            "\tTrain Loss: 0.157 | Train Acc: 94.24%\n",
            "\t Val. Loss: 0.324 |  Val. Acc: 87.09%\n"
          ]
        }
      ],
      "source": [
        "# How many training loops we want\n",
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'CNN-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpNkX3r2RXe2",
        "outputId": "02b87eb1-fa03-4fb2-eabb-b6d2fc6e9b4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.341 | Test Acc: 85.43%\n"
          ]
        }
      ],
      "source": [
        "# Evaluates model on the saved test data\n",
        "model.load_state_dict(torch.load('CNN-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKHiVZVDRiA2",
        "outputId": "2c0a9004-1f56-4eea-e9c9-86dde3bc1dcc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9876343011856079, 0.5197110176086426, 0.014556529931724072]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#Use English language\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def prediction(model, sentence, min_len = 5):\n",
        "    \"\"\"Function that predicts if the review is positive or negative,\n",
        "    Positive reviews mapped to 1, and negative to 0.\n",
        "    \"\"\"\n",
        "    \n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "    if len(tokenized) < min_len:\n",
        "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(0)\n",
        "    prediction = torch.sigmoid(model(tensor))\n",
        "    return prediction.item()\n",
        "\n",
        "\n",
        "reviews = ['This is the best movie I have ever watched!',\n",
        "           'This is an okay movie',\n",
        "           'This was a waste of time! I did not like this movie.']\n",
        "scores=[prediction(model,review) for review in reviews]\n",
        "scores"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "CNNzavrsni.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPf3BT/4xrSMAPnykujcTyg",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}